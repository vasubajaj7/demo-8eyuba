name: Airflow Migration Test Suite

on:
  push:
    branches:
      - feature/*
      - bugfix/*
      - dev
      - development
  pull_request:
    branches:
      - main
      - master
      - release/*
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        type: choice
        options:
          - all
          - unit
          - integration
          - migration
          - security
        default: 'all'

env:
  AIRFLOW_HOME: ${{ github.workspace }}/airflow
  AIRFLOW_VERSION: '2.0.0'
  PYTHONPATH: ${{ github.workspace }}
  CI: 'true'

permissions:
  contents: read
  security-events: write
  actions: read
  checks: write

concurrency:
  group: test-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' || github.event.inputs.test_type == 'unit' || github.event.inputs.test_type == 'migration'
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install development dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black==22.3.0 pylint==2.12.2 flake8==4.0.1 isort==5.10.1 mypy==0.942 bandit==1.7.4

      - name: Run black formatter check
        run: black --check src/

      - name: Run isort check
        run: isort --check-only --profile black src/

      - name: Run pylint
        run: pylint --rcfile=.pylintrc src/

      - name: Run flake8
        run: flake8 src/

      - name: Run mypy type checking
        run: mypy src/

      - name: Run security check with bandit
        run: bandit -r src/ -c .bandit.yml

  validate-dags:
    name: DAG Validation
    runs-on: ubuntu-latest
    needs: [lint]
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' || github.event.inputs.test_type == 'unit' || github.event.inputs.test_type == 'migration'
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-airflow-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-airflow-

      - name: Install Airflow and dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "apache-airflow==$AIRFLOW_VERSION" apache-airflow-providers-google apache-airflow-providers-postgres apache-airflow-providers-http
          pip install -r requirements.txt

      - name: Validate DAG files
        run: |
          mkdir -p ${AIRFLOW_HOME}
          python -m src.backend.scripts.validate_dags src/dags --format json --output validation-report.json --level WARNING

      - name: Generate compatibility report
        run: |
          python -m src.backend.scripts.validate_dags src/dags --format html --output compatibility-report.html --level WARNING

      - name: Upload validation results
        uses: actions/upload-artifact@v3
        with:
          name: dag-validation-reports
          path: |
            validation-report.json
            compatibility-report.html

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [validate-dags]
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' || github.event.inputs.test_type == 'unit'
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-unittest-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-unittest-

      - name: Install test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "apache-airflow==$AIRFLOW_VERSION" apache-airflow-providers-google apache-airflow-providers-postgres pytest pytest-cov pytest-xdist

      - name: Configure Airflow environment
        run: |
          mkdir -p ${AIRFLOW_HOME}
          export AIRFLOW__CORE__DAGS_FOLDER="${GITHUB_WORKSPACE}/src/dags"
          export AIRFLOW__CORE__LOAD_EXAMPLES=False
          export AIRFLOW__CORE__UNIT_TEST_MODE=True

      - name: Execute unit test script
        run: |
          bash src/test/ci/run_unit_tests.sh

      - name: Upload test reports
        uses: actions/upload-artifact@v3
        with:
          name: unit-test-reports
          path: test-reports/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: (github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' || github.event.inputs.test_type == 'integration') && (github.event_name == 'pull_request' || github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch')
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_USER: airflow
          POSTGRES_PASSWORD: airflow
          POSTGRES_DB: airflow
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:6
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-integration-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-integration-

      - name: Install integration test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "apache-airflow==$AIRFLOW_VERSION" apache-airflow-providers-google apache-airflow-providers-postgres apache-airflow-providers-http
          pip install pytest pytest-mock moto google-cloud-storage google-cloud-bigquery google-cloud-secretmanager

      - name: Set up environment variables
        run: |
          echo "AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@localhost:5432/airflow" >> $GITHUB_ENV
          echo "AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@localhost:5432/airflow" >> $GITHUB_ENV
          echo "AIRFLOW__CELERY__BROKER_URL=redis://localhost:6379/0" >> $GITHUB_ENV
          echo "GCP_PROJECT_ID=composer-migration-test" >> $GITHUB_ENV
          echo "GCP_REGION=us-central1" >> $GITHUB_ENV
          echo "MOCK_GCP_SERVICES=true" >> $GITHUB_ENV
          echo "RUN_DOCKER_SERVICES=false" >> $GITHUB_ENV
          echo "CI_BUILD_ID=${{ github.run_id }}" >> $GITHUB_ENV

      - name: Execute integration test script
        run: |
          bash src/test/ci/run_integration_tests.sh

      - name: Upload integration test reports
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-reports
          path: integration-test-reports/

  migration-compatibility:
    name: Migration Compatibility Tests
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' || github.event.inputs.test_type == 'migration'
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-migration-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-migration-

      - name: Set up Airflow 1.10.15 environment
        run: |
          python -m venv venv1
          source venv1/bin/activate
          pip install apache-airflow==1.10.15
          pip install pytest pytest-cov
          deactivate

      - name: Run Airflow 1.10.15 tests
        run: |
          source venv1/bin/activate
          mkdir -p airflow1-home
          export AIRFLOW_HOME="$GITHUB_WORKSPACE/airflow1-home"
          export AIRFLOW__CORE__DAGS_FOLDER="$GITHUB_WORKSPACE/src/dags"
          export AIRFLOW__CORE__LOAD_EXAMPLES=False
          export AIRFLOW__CORE__UNIT_TEST_MODE=True
          pytest -xvs src/test/compatibility/airflow1/ --junitxml=airflow1-test-results.xml
          deactivate

      - name: Set up Airflow 2.X environment
        run: |
          python -m venv venv2
          source venv2/bin/activate
          pip install "apache-airflow==$AIRFLOW_VERSION" apache-airflow-providers-google apache-airflow-providers-postgres apache-airflow-providers-http
          pip install pytest pytest-cov
          deactivate

      - name: Run Airflow 2.X tests
        run: |
          source venv2/bin/activate
          mkdir -p airflow2-home
          export AIRFLOW_HOME="$GITHUB_WORKSPACE/airflow2-home"
          export AIRFLOW__CORE__DAGS_FOLDER="$GITHUB_WORKSPACE/src/dags"
          export AIRFLOW__CORE__LOAD_EXAMPLES=False
          export AIRFLOW__CORE__UNIT_TEST_MODE=True
          pytest -xvs src/test/compatibility/airflow2/ --junitxml=airflow2-test-results.xml
          deactivate

      - name: Compare test results
        run: |
          mkdir -p migration-reports
          python src/test/tools/compare_test_results.py \
            --airflow1-results airflow1-test-results.xml \
            --airflow2-results airflow2-test-results.xml \
            --output migration-reports/migration-compatibility.json

      - name: Analyze deprecated features
        run: |
          python src/test/tools/analyze_deprecated_features.py \
            --dag-directory src/dags \
            --output migration-reports/deprecated-features.json
            
      - name: Generate TaskFlow API conversion suggestions
        run: |
          python src/test/tools/suggest_taskflow_conversions.py \
            --dag-directory src/dags \
            --output migration-reports/taskflow-suggestions.json

      - name: Upload compatibility report
        uses: actions/upload-artifact@v3
        with:
          name: migration-compatibility-reports
          path: migration-reports/

  container-tests:
    name: Container Tests
    runs-on: ubuntu-latest
    needs: [unit-tests]
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' || github.event.inputs.test_type == 'migration'
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Build Airflow container
        uses: docker/build-push-action@v4
        with:
          context: .
          file: ./Dockerfile
          load: true
          tags: airflow-migration:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Install test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest docker requests

      - name: Run container tests
        run: |
          # Start the container
          docker run -d --name airflow-test -p 8080:8080 \
            -e AIRFLOW__CORE__LOAD_EXAMPLES=False \
            -e AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True \
            airflow-migration:test

          # Wait for webserver to start
          python -c "import time, requests; time.sleep(30); \
            [time.sleep(5) for _ in range(12) if requests.get('http://localhost:8080/health').status_code != 200];"

          # Run the tests
          pytest -xvs src/test/container/

      - name: Verify Composer 2 compatibility
        run: |
          mkdir -p container-reports
          python src/test/tools/verify_composer2_compatibility.py \
            --container-id airflow-test \
            --output container-reports/composer2-compatibility.json

      - name: Upload container test results
        uses: actions/upload-artifact@v3
        with:
          name: container-test-reports
          path: container-reports/

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' || github.event.inputs.test_type == 'security'
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Initialize CodeQL
        uses: github/codeql-action/init@v2
        with:
          languages: python

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v2

      - name: Set up Python 3.8
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'

      - name: Install security scanning tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety detect-secrets

      - name: Run dependency vulnerability scan
        run: |
          mkdir -p security-reports
          safety check --output json > security-reports/dependency-check.json

      - name: Check for hardcoded secrets
        run: |
          detect-secrets scan --baseline .secrets.baseline > security-reports/secrets-scan.json

      - name: Run Bandit security scan
        run: |
          bandit -r src/ -f json -o security-reports/bandit-results.json

      - name: Upload security scan results
        uses: actions/upload-artifact@v3
        with:
          name: security-scan-reports
          path: security-reports/